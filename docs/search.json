[
  {
    "objectID": "preregistration.html",
    "href": "preregistration.html",
    "title": "1. Pre-Registration",
    "section": "",
    "text": "A preregistration is a document that outlines the plan for conducting research before any data is collected or analyzed. This document, which typically includes the introduction and methods sections of a research paper, serves as a time-stamped record of the research plan. At a minimum, a preregistration should include the hypotheses to be tested, the methodology and variables that will be used (including the design, sample, stopping rule, exclusion criteria, procedure, and variables), the analysis plan (including statistical tests, transformations, and assumption tests), and the criteria for inferring whether the hypotheses have been confirmed or rejected.\n\n\n\nThere are several reasons why you should consider preregistering your research:\n\nTo clearly distinguish between confirmatory and exploratory analyses and avoid presenting exploratory results as if they were hypothesized.\nTo maintain transparency, preventing selective reporting and p-hacking.\nTo contribute to reducing the file drawer problem and publication bias.\nTo serve as a safety net for your future self: by preregistering your research, you won’t have to rely on memory to recall your plans and methods. You’ll only need to execute your plan (and report any deviations from it).\nFor more reasons to preregister, you may want to read this article\n\n\n\n\nPreregistration can raise some dilemmas, but they are all easily addressed:\n\n“Preregistration costs too much time.” The time you spend on preregistration is time you would normally spend after data collection. Preregistration can save you time because you won’t waste time on pointless analyses; you’ve already written your introduction and methods sections.\n“What if my research doesn’t go according to plan?” You can add an addendum to your preregistration before the analysis to explain any deviations from the plan. Afterward, report any deviations in your manuscript. Transparency is the goal.\n“No one will ever look at my preregistration.” You can use the preregistration as a reminder for yourself, as a justification to reviewers of your manuscript, and to inspire colleagues and interested researchers with your open attitude. Go for it!\n\n\n\n\nSee this link for an easy tutorial on how to preregister on the Open Science Framework (OSF). Don’t forget to include your collaborators and include the link to your preregistration in your manuscript.\n\n\n\nRegistered Reports are a type of preregistration that undergoes peer review by journals. This greatly reduces publication bias because at Stage 1 peer review, reviewers do not know the results, so manuscripts cannot be accepted or rejected based on them. The process of Registered Reports is shown below:\n\n\n\nSource: https://eur-synclab.github.io/open-science/preregistration.html\n\n\nAfter your preregistration has received an In Principle Acceptance (Stage 1), you can start collecting data and writing up your results. Most journals that get through Stage 1 will also get accepted in Stage 2, because the study design has already been reviewed.\n\n\n\n\nAll OSF templates\nA list of resources on preregistration\nInformation about Registered Reports\nOverview of all journals doing Registered Reports\nA preregistration tutorial and template for secondary data analysis\nPreregistration: dream vs. reality"
  },
  {
    "objectID": "preregistration.html#resources",
    "href": "preregistration.html#resources",
    "title": "1. Pre-Registration",
    "section": "",
    "text": "All OSF templates\nA list of resources on preregistration\nInformation about Registered Reports\nOverview of all journals doing Registered Reports\nA preregistration tutorial and template for secondary data analysis\nPreregistration: dream vs. reality"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Guidelines",
    "section": "",
    "text": "Use the following criteria to guide and “evaluate” the Open Science level of a specific study (when available, follow the links for wiki pages on each topic). Most links point to the Open Science Framework, but other trusted platforms are available.\n\n\n\n\nWrite a pre-registration or registered report and upload it on OSF Registries\n\n\n\nCheck/write a data management plan (DMP)\n\n\n\n\n\n\nUse and store understandable and accessible protocols for data collection, including protocols for participant contact, participant instructions, and data handling.\n\n\n\nKeep a codebook that gives an overview all the different measures and the exact content of data files. This includes information like variable names and labels, measurement levels and values. This can be a template at first and be updated it if changes occur.\n\n\n\nKeep a logbook of all important events that occur during data collection\n\n\n\nStore your data logically and in a safe place from day 1\n\n\n\nUse understandable and accessible scripts/syntax for data analyses\n\n\n\nUse understandable and accessible Readme to describe research metadata.\n\n\n\n\n\n\nImplement version control when writing your paper/analyzing your data (i.e. using Github or Datalad)\n\n\n\nUpload your final manuscript as a preprint to an official repository such as OSF Preprints\n\n\n\nSubmit your final manuscript for peer review using always the Open Access option for that journal\n\n\n\n\n\n\nList your published paper on the ICArEHB website by sending the complete reference to our Admin Office\n\n\n\nWrite a message on your personal Twitter, LinkedIn, Facebook, etc.\n\n\n\nWrite a message for ICArEHB’s Twitter, LinkedIn, Facebook, etc.\n\n\n\n\n\n\n\nSource: https://jamesbrandscience.github.io/tutorials/open_science/Introduction.html#1"
  },
  {
    "objectID": "intro.html#preparing-the-study",
    "href": "intro.html#preparing-the-study",
    "title": "Guidelines",
    "section": "",
    "text": "Write a pre-registration or registered report and upload it on OSF Registries\n\n\n\nCheck/write a data management plan (DMP)"
  },
  {
    "objectID": "intro.html#conducting-the-study",
    "href": "intro.html#conducting-the-study",
    "title": "Guidelines",
    "section": "",
    "text": "Use and store understandable and accessible protocols for data collection, including protocols for participant contact, participant instructions, and data handling.\n\n\n\nKeep a codebook that gives an overview all the different measures and the exact content of data files. This includes information like variable names and labels, measurement levels and values. This can be a template at first and be updated it if changes occur.\n\n\n\nKeep a logbook of all important events that occur during data collection\n\n\n\nStore your data logically and in a safe place from day 1\n\n\n\nUse understandable and accessible scripts/syntax for data analyses\n\n\n\nUse understandable and accessible Readme to describe research metadata."
  },
  {
    "objectID": "intro.html#writing-the-manuscript",
    "href": "intro.html#writing-the-manuscript",
    "title": "Guidelines",
    "section": "",
    "text": "Implement version control when writing your paper/analyzing your data (i.e. using Github or Datalad)\n\n\n\nUpload your final manuscript as a preprint to an official repository such as OSF Preprints\n\n\n\nSubmit your final manuscript for peer review using always the Open Access option for that journal"
  },
  {
    "objectID": "intro.html#after-publication",
    "href": "intro.html#after-publication",
    "title": "Guidelines",
    "section": "",
    "text": "List your published paper on the ICArEHB website by sending the complete reference to our Admin Office\n\n\n\nWrite a message on your personal Twitter, LinkedIn, Facebook, etc.\n\n\n\nWrite a message for ICArEHB’s Twitter, LinkedIn, Facebook, etc."
  },
  {
    "objectID": "intro.html#ideal-workflow",
    "href": "intro.html#ideal-workflow",
    "title": "Guidelines",
    "section": "",
    "text": "Source: https://jamesbrandscience.github.io/tutorials/open_science/Introduction.html#1"
  },
  {
    "objectID": "metadata.html",
    "href": "metadata.html",
    "title": "8. Metadata",
    "section": "",
    "text": "8. Metadata\nMetadata refers to data that describes other data. In other words, it’s information about the content, context, quality, and other characteristics of a dataset. Metadata can include details such as the dataset’s title, author, date created, variable definitions, and data format.\nMetadata is crucial for achieving FAIR data, which stands for Findable, Accessible, Interoperable, and Reusable. Without appropriate metadata, it can be difficult or impossible to find, understand, or effectively use a dataset. For example, if a researcher wants to locate data on a particular topic, they may rely on metadata to search for and identify relevant datasets. Similarly, metadata can help ensure that data are properly documented, formatted, and described, facilitating their use by other researchers. Metadata plays a critical role in enhancing the discoverability, usability, and overall value of research data.\n\nExamples of research metadata\n\nA project readme containing the information below. Often in a readme.txt. Find an example template here or use the information below:\n\nCreator (PI): name and affiliation of PI\nTitle: project title\nFunding sources: names of funders, incl. grant numbers and related acknowledgements\nData collector/producer: who is responsible for data collection + date and location of data production\nDescription: project description, incl. relevant publications\nSample and sampling procedures: target population and methods to sample it (or link to document describing this), retention rates for longitudinal studies\nCoverage: topics, time period and location covered\nSource: if relevant, citations to original source from which data were obtained\n\nMetadata for a specific data file, containing, for example, file description, data format, relationship with other files, date of creation and versioning information, etc. This can be a readme.txt or other filetypes, such as nameofdatafile.json or nameofdatafile.xml\nA codebook (data dictionary), which specifies what all variables in your dataset mean. See Data Dictionary for more information.\n\nQuestion wording or meaning\nVariable text: question text or item number\nRespondent: who was asked the question?\nMeaning of codes: interpretation of the codes assigned to each variable\nMissing data codes, e.g., 999\nSummary statistics for both valid and missing cases\nImputation and editing: identify data that have been estimated or extensively edited\nConstructed and weight variables: how were they constructed\nLocation in the data file: field or column location, if relevant\nVariable groupings: if you categorize variables into conceptual groupings\n\nMetadata in systems, such as a data repository. This type of metadata is often enforced and interoperable so that you don’t have to manually create this type of metadata.\n\n\n\nMetadata standards\nMetadata standards refer to the frameworks that provide guidelines for the metadata fields, defining the formatting of metadata fields to make them machine-readable and interoperable. An extensive range of metadata standards is available, varying across different disciplines. For the social sciences, the most widely known metadata standards are Dublin Core and Data Documentation Initiative (DDI). Dublin Core consists of basic elements for describing networked resources, such as Title, Creator, Subject, Description, Publisher, Contributor, Date, Type, Format, and Identifier, among others (check this metadata file generator to see all the elements). On the other hand, DDI is commonly used in social, behavioral, economic, and health sciences, including CESSDA (Consortium of European Social Science Data Archives). Researchers may not always need to work directly with these standards, but it is important to understand that different repositories may adopt different standards. More metadata standards can be found here."
  },
  {
    "objectID": "preprints.html",
    "href": "preprints.html",
    "title": "10. Preprints",
    "section": "",
    "text": "10. Preprints\nPreprints are early versions of research papers that have not yet undergone peer review or been published in a scientific or academic journal. They are typically posted on preprint servers, which are online repositories that allow authors to share their work with the wider research community before publication.\nPreprints often contain preliminary results or research findings that are still being refined or validated. They are intended to facilitate the dissemination of research findings and enable early feedback and collaboration among researchers.\nPreprints are becoming increasingly popular in many scientific disciplines, including physics, biology, computer science, and archaeology. They offer several benefits, such as faster dissemination of research, increased collaboration opportunities, and the ability to receive feedback from a wider range of experts in the field.\nSee more info in this Preprint FAQ\n\nWhy publish preprints?\nThere are several reasons why researchers choose to publish preprints:\n\nRapid dissemination of research findings: Preprints enable researchers to share their work quickly and easily with the wider scientific community, leading to more rapid dissemination of research findings.\nIncreased visibility and impact: By making their research available as a preprint, researchers can increase the visibility and impact of their work, as it can be accessed and cited by other researchers before it is formally published.\nEarly feedback and collaboration: Preprints allow researchers to receive early feedback and engage in collaborative discussions with other experts in their field, which can help to improve the quality of their research.\nAvoidance of long review processes: Formal peer review can be a lengthy and time-consuming process. Publishing preprints can reduce the time from submission to publication, as it enables researchers to receive feedback and make revisions before submitting their work to a journal.\nOpen science and transparency: Publishing preprints is part of a growing movement towards open science and transparency in research, which aims to make scientific findings more accessible to the public and increase trust in scientific research.\n\n\n\nWhere to publish preprints?\nPreferably a preprint server that provides a persistent identifier. For example:\n\nOSF Preprints: you can choose many preprint servers and can also share supplementary files. A list of preprint servers hosted via OSF Preprints can be found here.\nDirectly via a preprint server, such as BioRxiv or PsyArXiv\nYou can even add a preprint on ResearchGate!\n\n\n\nFeedback and updating\nResearchers can give/receive feedback on preprints in different ways: - In OSF preprints, you can use their tool Hypothes.is to annotate preprints, see their help guide.\nWhat you do with feedback is completely up to you. If you want, you can update your preprint to a new version. However, note that all versions are timestamped and retained. Often new versions get a new identifier (DOI) and old versions cannot be removed. If your work gets published by a publisher, many preprint servers also offer the possibility to refer to the identifier (DOI) of your published work, so that readers of the preprint get a notification that they are not reading the most up-to-date version."
  },
  {
    "objectID": "scripts.html",
    "href": "scripts.html",
    "title": "7. Scripts",
    "section": "",
    "text": "7. Scripts\nSharing analysis code in research has several benefits, including:\n\nReproducibility: Sharing code allows other researchers to replicate your analysis and verify your findings. This is important because reproducibility is a fundamental aspect of scientific research.\nTransparency: Sharing code makes your research more transparent by allowing others to see exactly how you conducted your analysis. This helps to build trust in your results and allows others to build upon your work.\nEfficiency: Sharing code can save other researchers time and effort by allowing them to build upon your work instead of starting from scratch. This can lead to more rapid progress in a field of study.\nCollaboration: Sharing code can facilitate collaboration between researchers by allowing them to easily share their work and build upon each other’s ideas.\nEducation: Sharing code can be a valuable educational resource for students and other researchers who are interested in learning new techniques or methods.\n\nOverall, sharing analysis code in research can help to promote open science and advance the progress of scientific research.\nWeb-based technologies make it very easy to share these materials (and even to share the complete software environment using Docker and Singularity containers). However, just releasing your code without annotation is not very informative because others (and future you!) can’t make a lot of sense of it. Two helpful tools to annotate your code are RMarkdown and Jupyter notebooks.\nR Markdown and Jupyter notebooks are tools that allow researchers to create executable documents that combine code, text, and data. These tools make research more reproducible in several ways:\n\nDocumentation: R Markdown and Jupyter notebooks allow researchers to document their analysis in real-time, making it easier for others to understand the steps taken in the analysis.\nVersion control: These tools allow researchers to track changes to their analysis and code over time, making it easier to reproduce previous analyses and results.\nCode sharing: R Markdown and Jupyter notebooks allow researchers to share their code and data with others, making it easier to reproduce their analysis.\nReproducibility: By combining code, text, and data in a single document, R Markdown and Jupyter notebooks make it easier for others to reproduce a researcher’s analysis and results. This helps to ensure that research findings are accurate and reliable.\nCollaboration: R Markdown and Jupyter notebooks make it easy for researchers to collaborate on an analysis, by allowing them to share and edit the same document."
  },
  {
    "objectID": "datadictionary.html",
    "href": "datadictionary.html",
    "title": "4. Data Dictionary",
    "section": "",
    "text": "4. Data Dictionary\nA data dictionary or a code book serves as a guide for interpreting the metadata of your data files, explaining the meanings of variable names and values. By providing clear documentation of your data, a codebook can enhance the reproducibility of your research. It can be particularly useful for facilitating collaborations and ensuring that you and others can understand and use the data in the future. Additionally, if you intend to share your datasets, creating a codebook is strongly recommended.\nPrior to embarking on the creation of a data dictionary, it may be advisable to peruse this introductory guide on producing codebooks and datasets that can be readily shared:\nBuchanan, E. M., Crain, S. E., Cunningham, A. L., Johnson, H. R., Stash, H. E., Papadatou-Pastou, M., … Aczel, B. (2019, May 20). Getting Started Creating Data Dictionaries: How to Create a Shareable Dataset. https://doi.org/10.31219/osf.io/vd4y3\nIf you use R to analyze your data, you can use the codebook package to create a codebook based on the dataframe you are working with."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "The core mission of ICArEHB is to build an integrative understanding of human behavior in prehistoric times and assure that the main outputs of this research are new and outstanding knowledge, ideas, and understanding in the fields of prehistoric archaeology and human evolution, that can be shared with other scientists and with the society.\nParticularly, the destructive nature of archaeology means that we must stick to the highest standards; we must leave a maximum of elements available for other scientists and the future generation of archaeologists. To keep these standards, ICArEHB embraces the concept of Open Science, i.e., research that is transparent and allows reproducibility, the best guarantee to stay at the forefront. It means that, as much as possible, our research projects are validated by our peers before we start it, our procedures, software, and code, are made accessible to others, and our results are shared with various audiences (e.g., other scientists, the general public, policymakers) and our data are archived for the future.\n\n\nDid you know that even before it starts, projects can be examined and validated by other experts? This is the case for all projects funded in ICArEHB, which go through peer review either by the third-party funder or by an internal review process.\nIn addition, we encourage our researchers to pre-register their study in journals and platforms allowing this format. This ensures that our study plans are robust and helps to reduce the bias of publication, so all results are shared, even if less exciting than expected.\n\n\n\nAs much as possible, we use open-source software and file formats that everyone can use. When we write code, or new software and apps, we publish them and assure that they are available for the rest of the community. Check out some of these examples here and here.\n\n\n\nOur scientific outputs are published in the form of articles, monographs, handbooks, etc., privileging those platforms that will make our research most visible to our peers, the scientific community, and the general public.\nIn ICArEHB, all articles led by our integrated researchers are in Open Access on the journal website or on the platform of publication. This means that we prefer to pay to make sure that everyone can have access to our production instead of asking the readers to pay. You can consult our list of publications and respective links here. \n\n\n\nScientific publication is not a piece of cake, especially if you are not used to it. In ICArEHB, we make a special effort to share our results and our conclusions with other parts of society, with adapted media. The Science Communication Lab is dedicated to inventing new formats and producing content for our outreach actions. \nCheck here our past and future events of outreach. If you would like ICArEHB to participate in school activities or in a fair, please contact us to discuss possibilities.\nWe exchange updates on good practices in archaeology through our collaboration with the company of contractual archaeology ERA Arqueologia.\nWe also make special efforts to transform scientific work into policy when necessary.\n\n\n\nPublications and communications are just the tip of the iceberg when it comes to research, and the text, tables, and images that we publish are just elements of a frontpage advertisement to the many hours of recording, processing, and analysis of what is one of the most valuable ICArEHB’s contributions to the world: our data!\nFactual data is the cornerstone of science, and access to data is crucial in fully understanding and extending the work of others. Providing free and general access to our data is the most effective way of ensuring that the fruits of the research can be accessed, read, and used as the basis for further research.\nBringing together the current demands of funding agencies with our will to transform the way people share archaeological data, ICArEHB offers a series of guidelines to researchers, so they can assess the open science level of a specific study, publication, or project.\nThis guide tries to tackle most of the current demands for open science. It is built around the use of trusted platforms that can support our researchers throughout their entire project lifecycle, centralizing as much as possible the different parts of the process, including Preregistrations, Data Storage and Versioning, Pre-prints, License attribution, Persistent Identifier Creation, Metadata creation for maximum machine-actionable Findability, Accessibility, Interoperability, and Re-usability (FAIR)."
  },
  {
    "objectID": "index.html#our-vision-of-open-science",
    "href": "index.html#our-vision-of-open-science",
    "title": "",
    "section": "",
    "text": "The core mission of ICArEHB is to build an integrative understanding of human behavior in prehistoric times and assure that the main outputs of this research are new and outstanding knowledge, ideas, and understanding in the fields of prehistoric archaeology and human evolution, that can be shared with other scientists and with the society.\nParticularly, the destructive nature of archaeology means that we must stick to the highest standards; we must leave a maximum of elements available for other scientists and the future generation of archaeologists. To keep these standards, ICArEHB embraces the concept of Open Science, i.e., research that is transparent and allows reproducibility, the best guarantee to stay at the forefront. It means that, as much as possible, our research projects are validated by our peers before we start it, our procedures, software, and code, are made accessible to others, and our results are shared with various audiences (e.g., other scientists, the general public, policymakers) and our data are archived for the future.\n\n\nDid you know that even before it starts, projects can be examined and validated by other experts? This is the case for all projects funded in ICArEHB, which go through peer review either by the third-party funder or by an internal review process.\nIn addition, we encourage our researchers to pre-register their study in journals and platforms allowing this format. This ensures that our study plans are robust and helps to reduce the bias of publication, so all results are shared, even if less exciting than expected.\n\n\n\nAs much as possible, we use open-source software and file formats that everyone can use. When we write code, or new software and apps, we publish them and assure that they are available for the rest of the community. Check out some of these examples here and here.\n\n\n\nOur scientific outputs are published in the form of articles, monographs, handbooks, etc., privileging those platforms that will make our research most visible to our peers, the scientific community, and the general public.\nIn ICArEHB, all articles led by our integrated researchers are in Open Access on the journal website or on the platform of publication. This means that we prefer to pay to make sure that everyone can have access to our production instead of asking the readers to pay. You can consult our list of publications and respective links here. \n\n\n\nScientific publication is not a piece of cake, especially if you are not used to it. In ICArEHB, we make a special effort to share our results and our conclusions with other parts of society, with adapted media. The Science Communication Lab is dedicated to inventing new formats and producing content for our outreach actions. \nCheck here our past and future events of outreach. If you would like ICArEHB to participate in school activities or in a fair, please contact us to discuss possibilities.\nWe exchange updates on good practices in archaeology through our collaboration with the company of contractual archaeology ERA Arqueologia.\nWe also make special efforts to transform scientific work into policy when necessary.\n\n\n\nPublications and communications are just the tip of the iceberg when it comes to research, and the text, tables, and images that we publish are just elements of a frontpage advertisement to the many hours of recording, processing, and analysis of what is one of the most valuable ICArEHB’s contributions to the world: our data!\nFactual data is the cornerstone of science, and access to data is crucial in fully understanding and extending the work of others. Providing free and general access to our data is the most effective way of ensuring that the fruits of the research can be accessed, read, and used as the basis for further research.\nBringing together the current demands of funding agencies with our will to transform the way people share archaeological data, ICArEHB offers a series of guidelines to researchers, so they can assess the open science level of a specific study, publication, or project.\nThis guide tries to tackle most of the current demands for open science. It is built around the use of trusted platforms that can support our researchers throughout their entire project lifecycle, centralizing as much as possible the different parts of the process, including Preregistrations, Data Storage and Versioning, Pre-prints, License attribution, Persistent Identifier Creation, Metadata creation for maximum machine-actionable Findability, Accessibility, Interoperability, and Re-usability (FAIR)."
  },
  {
    "objectID": "datacollection.html",
    "href": "datacollection.html",
    "title": "3. Data Collection Protocols",
    "section": "",
    "text": "3. Data Collection Protocols\nSoon available"
  },
  {
    "objectID": "dmp.html",
    "href": "dmp.html",
    "title": "2. Data Management Plan (DMP)",
    "section": "",
    "text": "A data management plan (DMP) is a document that outlines how data will be collected, organized, stored, preserved, and shared during a research project. A DMP is usually required by funding agencies, publishers, or institutions as a way to ensure that research data are managed appropriately and meet legal, ethical, and practical standards.\n\n\n\nThe main components of a DMP may include:\n\nDescription of the data: What type of data will be collected or generated, and how will they be structured?\nData collection methods: How will the data be collected (e.g., surveys, experiments, observations), and what tools or equipment will be used?\nData organization and documentation: How will the data be named, labeled, and organized to ensure consistency and usability?\nData storage and backup: Where and how will the data be stored (e.g., local servers, cloud-based platforms), and how often will they be backed up?\nData sharing and reuse: Who will have access to the data, under what conditions, and for what purposes?\nData retention and preservation: How long will the data be kept, and how will they be preserved and made accessible after the end of the project?\n\n\n\n\n\nIdentify the key data types and formats you will collect or generate during your research project.\nDetermine how you will organize and store the data. Consider factors such as security, backup, and accessibility.\nDecide how you will manage any ethical or legal issues related to your data. This may involve obtaining informed consent from participants, ensuring compliance with privacy regulations, or addressing intellectual property rights.\nEstablish guidelines for documenting your data. This may include creating metadata, labeling your files, and maintaining a data dictionary.\nDevelop a plan for sharing your data. Consider what data should be shared, with whom, and under what conditions.\nDevelop a plan for preserving your data after completing your project. Consider how long you will need to keep the data and how you will ensure that it remains accessible and usable.\n\nSome funding agencies, institutions, or publishers may provide templates or guidelines for writing a DMP. Additionally, there are several online tools available, such as the DMPTool, DataOne, or Argos that can help guide you through the process of creating a DMP tailored to your specific needs.\nWhen writing your DMP, it is important to be as specific as possible and to consider all aspects of your data management strategy. Consult with colleagues or data management experts if you need guidance or feedback.\n\n\n\n\nMore information about data management (storing, archiving, versioning, data structure, etc.) and backing up and versioning data\nHow to name your files\nThe costs of data management\nMore about privacy and legal aspects\nFCT DMP template\nERC DMP template"
  },
  {
    "objectID": "dmp.html#resources",
    "href": "dmp.html#resources",
    "title": "2. Data Management Plan (DMP)",
    "section": "",
    "text": "More information about data management (storing, archiving, versioning, data structure, etc.) and backing up and versioning data\nHow to name your files\nThe costs of data management\nMore about privacy and legal aspects\nFCT DMP template\nERC DMP template"
  },
  {
    "objectID": "peerreview.html",
    "href": "peerreview.html",
    "title": "11. Peer review",
    "section": "",
    "text": "11. Peer review\nSoon available"
  },
  {
    "objectID": "logbook.html",
    "href": "logbook.html",
    "title": "5. Logbook",
    "section": "",
    "text": "5. Logbook\nSoon available"
  },
  {
    "objectID": "versioncontrol.html",
    "href": "versioncontrol.html",
    "title": "9. Version Control",
    "section": "",
    "text": "9. Version Control\nVersion control of files is the practice of tracking changes made to a file over time, creating a history of revisions that can be reviewed, reverted, or compared. It involves using specialized software tools that allow users to manage and store different versions of a file, along with associated metadata such as timestamps, authorship, and comments.\nVersion control is commonly used in software development to manage the source code of a project, but it can also be applied to any type of file, including text documents, spreadsheets, graphics, and multimedia files. By keeping different versions of a file separated and organized, version control helps to avoid data loss, reduce errors, and enable collaboration among multiple users working on the same file.\nIt is highly recommended to make a habit out of at least one, but preferably more of the following practices if you do not (want to) use a formal version control system:\n\nKeep raw data separately from any processed data and document which steps have been taken to go from the former to the latter\nRename a file every time you make a sizable change\nUse dates in the filename in the format YYYYMMDD\nAppend the filename with a version number, e.g., document_v1.0, document_v1.2, etc.\nSee this link for a helper document for coming up with a good file naming convention\nInclude a versioning history within the document, e.g., on the first page, explaining what changed in which version\nUse services like Google drive and Dropbox, which allow collaborative editing but also reverting to previous versions\n\n\nFormal Version Control Systems\nFormal version control systems are software tools that are designed to help manage changes to files, particularly source code files in software development projects. They enable users to track modifications made to a file over time, store different versions of the file, and collaborate with other users. Formal version control systems typically provide features such as:\n\nCheck-in and check-out of files\nVersion history tracking\nBranching and merging of files\nAccess control and permission management\nAnnotation and commenting on changes\nDiff and merge tools for comparing versions\nIntegration with other development tools and platforms\n\nExamples of formal version control systems include Git, Subversion (SVN), Mercurial, and Perforce. These systems are widely used in software development teams and other collaborative projects where file versioning, change tracking, and collaboration are critical."
  },
  {
    "objectID": "datastorage.html",
    "href": "datastorage.html",
    "title": "6. Data Storage",
    "section": "",
    "text": "6. Data Storage\nSoon available"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "References"
  }
]